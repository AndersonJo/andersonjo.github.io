---
layout: post
title:  "Exem - Predika.io"
date:   2016-03-02 01:00:00
categories: "portfolio"
static: /assets/posts/Exem/
tags: []
---

<img src="{{ page.static }}PredikaIO.png" class="img-responsive img-rounded">

# Sinsinsa Machines + Hadoop
신신사에서 나온 기계 관련 정보를 티라유텍에서 센서장비들을 이용해서 데이터를 수집합니다. 
수집된 데이터는 Kafka 또는 Queue를 통해서 실시간으로 HDFS또는 Predika서버로 보내게 됩니다.
로그데이터이므로 수집된 데이터의 양은 시간이 갈수록 매우 커질것으로 예상이 됩니다.
따라서 HDFS또는 S3 + AWS EMR 사용이 있을것으로 예상됩니다.
또한 플라밍고또는 MapReduce를 통한 Semi-structured Data에 대한 전처리 작업이 있을것으로 생각됩니다.

# Rhino Server
Rhino server는 AWS EC2 + Lambda + S3 서버로 구성이 되어 있으며, 
Static web server + Lambda + S3의 활용으로 서버비용을 극적으로 줄일것으로 예상이 되며, 
(추후 개발요건에 따라 EC2사용이 될 수 도 있습니다.)
필요 기술
Ruby
Jekyll (Static Website)
S3 
Cloudfront 
Angular.js
Fabric
 
# MOM's Oracle Database  
실질적으로 데이터분석에 필요한 데이터들이 여기에 다 몰려있으며, 해당 데이터는 
Predika Server에서 설정해놓은데로, 주기적으로 데이터를 클라우드로 가져가게 됩니다. 즉 Predika Server로 데이터가 보내지게 됩니다.

# Predika Server
사용자로부터 받아진 데이터는 이곳에서 분석이 이루어 지게 됩니다.
하둡 사용의 경우 Flamingo 등을 사용하지만, 대부분의 데이터 분석작업은 Redshift를 통해서 데이터분석작업이 이루어 질것으로 예상됩니다. 
최종적 분석된 데이터는 여러대의 MariaDB에 저장이 되며, 빠른 결과물을 출력하기 위해서 Redis Cache를 여러대 사용하게 됩니다.
Predika의 최종적인 모습은 하둡의 빅데이터가 아닌 데이터에 좀 더 초점을 맞추며, distributed GPU Clustering을 통해서 
현재 구글 딥마인드가 구현하는 것처럼 딥러닝에 주요 초점이 맞출 생각입니다. 
필요기술
TensorFlow for distributed GPU computation
Docker
Python Numpy, Scipy
Python Django
Python Fabric for deployment 
AWS
Kafka, Hadoop, Hive
Node.js for WebSocket