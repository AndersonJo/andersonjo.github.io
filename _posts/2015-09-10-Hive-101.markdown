---
layout: post
title:  "Hive 101"
date:   2015-9-10 01:00:00
categories: "hadoop"
asset_path: /assets/posts/Hive-101/
---
<div>
    <img src="{{ page.asset_path }}hive.jpg" class="img-responsive img-rounded">
</div>

# Hadoop Ecosystem 

| Tool | Description |
|:--|:--|
| Scoop | HDFS 와 RDBMS 사이의 데이터를 Import, Export할 수 있는 툴 |
| Pig | Procedural language platform으로서 Map Reduce를 위한 스크립트를 짜게 해줌 |
| Hive | Map Reduce에 대해서 SQL Query 타입 유형의 스크립트를 짜게 해줌 |
 
Map Reduce를 할 수 있는 방법 

* 기존의 Java Map Reduce 방법 
* Pig로 스크립트를 짜서 structured or semi structured data를 처리함 
* Hive로 SQL Query문으로 structured data를 처리함 (Hive Query Language)


# Installing Hive

### Installing Hive 

[Download Page][download-page]에 들어가서 Hive를 다운 받습니다.

{% highlight bash %}
tar -zxvf apache-hive-1.2.1-bin.tar.gz
sudo mkdir /usr/local/hive
sudo mv apache-hive-1.2.1-bin/* /usr/lib/hive/
{% endhighlight %}

### Setting Hive Environment

.bashrc에 다음을 넣습니다.

{% highlight bash %}
export JAVA_HOME=/usr/lib/jvm/java-7-oracle
export HADOOP_HOME=/usr/local/hadoop-2.7.1
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/conf
export HADOOP_CLASSPATH=/usr/local/hadoop-2.7.1/conf
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
export HIVE_HOME="/usr/local/hive"

export CLASSPATH=$CLASSPATH:$HIVE_HOME/lib/*:.
export CLASSPATH=$CLASSPATH:$HADOOP_HOME/lib/*:.

export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HIVE_HOME/bin
{% endhighlight %}

### yarn-site.xml

{% highlight xml %}
<configuration>
   <property>
      <name>yarn.nodemanager.aux-services</name>
      <value>mapreduce_shuffle</value>
   </property>
   <property>
      <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
      <value>org.apache.hadoop.mapred.ShuffleHandler</value>
   </property>
</configuration>

{% endhighlight %}

### mapred-site.xml

mapred-site.xml은 어떤 MapReduce 엔진을 사용하는지 지정을 합니다.<br>
먼저 

{% highlight bash %}
cp mapred-site.xml.template mapred-site.xml
{% endhighlight %}

{% highlight xml %}
<configuration>
   <property>
      <name>mapreduce.framework.name</name>
      <value>yarn</value>
   </property>
</configuration>
{% endhighlight %}



### Verifying

{% highlight bash %}
hdfs namenode -format
start-dfs.sh
start-yarn.sh
{% endhighlight %}

Hadoop Configuration 화면이 나와야 합니다.

<strong style="color:red;">[http://localhost:50070][dfs]</strong>


### Configuring Hive

HIVE_HOME안의 conf디렉토리에 있는 hive-env.sh를 설정해주면 됩니다.<br>
conf 디렉토리 안에는 이미 템플렛 파일이 있기 때문에 그냥 카피해주면 됩니다.

{% highlight bash %}
cp hive-env.sh.template hive-env.sh
{% endhighlight %}


# Apache Derby

### Installing Derby

Apache Derby는 Java로 만들어진 Relational Database입니다.<br>
[Derby Download Page][derby-download-page] 에 접속해서 wget으로 받습니다.

다운받은 파일을 풀고 /usr/local/derby 위치고 카피시켜줍니다.

{% highlight bash %}
sudo mv db-derby-10.12.1.1-bin /usr/local/derby
cd /usr/local
sudo chown -R hduser:hadoop derby
{% endhighlight %}


### Configuring Derby

.bashrc에 다음을 추가합니다.

{% highlight bash %}
export DERBY_HOME=/usr/local/derby
export PATH=$PATH:$DERBY_HOME/bin

export CLASSPATH=$CLASSPATH:$DERBY_HOME/lib/derby.jar
export CLASSPATH=$CLASSPATH:$DERBY_HOME/lib/derbytools.jar
{% endhighlight %}

메타데이터가 저장될 공간을 만들면 끝입니다.
{% highlight bash %}
mkdir $DERBY_HOME/data
{% endhighlight %}

# Metastore of Hive

{% highlight bash %}
cd $HIVE_HOME/conf
cp hive-default.xml.template hive-site.xml
{% endhighlight %}


# Verifying Hive Installation

{% highlight bash %}
hdfs dfs -mkdir /hive/warehouse
hdfs dfs -mkdir -p /hive/warehouse
hdfs dfs -chmod g+w /tmp
hdfs dfs -chmod g+w /hive/warehouse
hive
{% endhighlight %}


[download-page]:http://apache.claz.org/hive/stable/
[derby-download-page]:https://db.apache.org/derby/derby_downloads.html
[dfs]: http://localhost:50070
[cats.csv]: {{ page.asset_path }}cats.csv