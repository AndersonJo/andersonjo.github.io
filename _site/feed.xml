<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anderson Jo 헤헤헤</title>
    <description>개발자 조창민입니다. Machine Learning, Python, Django, R, Android, AWS, Game Server, Startup 등등 다양한 경험을 갖고 있는 개발자 입니다.</description>
    <link>http://andersonjo.github.io//</link>
    <atom:link href="http://andersonjo.github.io//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 05 Aug 2015 14:42:21 +0900</pubDate>
    <lastBuildDate>Wed, 05 Aug 2015 14:42:21 +0900</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Naive Bayes</title>
        <description>&lt;p&gt;Bayes 공식이나 이론은 이미 &lt;a href=&quot;/machine-learning/2015/07/29/Monty-Hall-Problem/&quot;&gt;Monty Hall&lt;/a&gt; 문제를 풀면서 설명을 했습니다.&lt;/p&gt;

&lt;p&gt;오늘은 이 Bayes 공식을 이용한.. 정말 간단하지만 왠만한 복잡도 높은 다른 classification methods 보다 강력한 퍼포먼스(정확도)를
보여주는 Naive Bayes를 예제와 함께 설명하겠습니다.&lt;/p&gt;

&lt;p&gt;일단 Naive Bayes의 공식은 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/Naive-Bayes/naive-bayes-formula.gif&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;C&lt;sub&gt;L&lt;/sub&gt; 은 클래스 또는 분류를 나타냅니다.&lt;/li&gt;
  &lt;li&gt;F 는 features&lt;/li&gt;
  &lt;li&gt;1/Z 는 scaling factor&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위의 공식 맨 오른쪽에 보면 P(F|C) 요런게 있는데 결국 conditional probability입니다.&lt;br /&gt;
하지만 Naive Bayes는 각각의 multiple 기호 안에 있는 likelihood 들이 모두 independent하다고 가정을 합니다.
즉 서로 영향을 미치지 않고 동전 앞이 나올지 뒤가 나올지 여러번 던지듯이 서로 연관성이 없다고 가정을 하고 들어갑니다.&lt;/p&gt;

&lt;p&gt;이유는 서로간에 dependent하다면 계산방식이 매우 복잡해지며 효율적인 알고리즘으로 사용하기 적합하지 않기 때문입니다.
그럼에도 Naive Bayes는 왠만한 복잡도 있는 machine learning 알고리듬에 비해서 매우 강력한 성능을 보여줍니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/Naive-Bayes/what-the-fuck.jpg&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;대체 뭔 소리여 ㅋㅋㅋ&lt;br /&gt; 
그냥 예제하나 풀면 다 이해됩니다.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;/assets/posts/Naive-Bayes/data.csv&quot;&gt;데이터 다운로드&lt;/a&gt;&lt;br /&gt;
&lt;em&gt;데이터는 &lt;a href=&quot;http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/&quot;&gt;Unicamp&lt;/a&gt; 에서 가져왔습니다.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.amazon.com/Machine-Learning-R-Brett-Lantz/dp/1782162143/ref=sr_1_1?ie=UTF8&amp;amp;qid=1438737465&amp;amp;sr=8-1&amp;amp;keywords=machine+learning+with+r&quot;&gt;Machine Learning With R&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;sms-spam-classification&quot;&gt;SMS Spam Classification&lt;/h1&gt;

&lt;p&gt;문자중에는 스팸 문자도 있고, 친구한테서 온 문자들도 있습니다.&lt;br /&gt;
아마도 스팸문자 안에는 ‘할인’, ‘비아그라’, ‘세일’ 같은 단어들이 많을거라 생각됩니다.&lt;br /&gt;
친구나 연인끼리의 문자를 보냈다면 ‘지금’, ‘집’, ‘어디’, ‘간다’, ‘사랑’ 같은 단어들이 좀 더 많이 있지 않을까 추측해 봅니다.&lt;/p&gt;

&lt;p&gt;자! 포인트는 이러한 스팸에서 나오는 단어들 그리고 친구나 연인끼리의 문자에서 나오는 단어들을 features로 삼아서 
확률적으로 해당 문자가 스팸인지 또는 햄(ham : 스팸이 아닌 문자)인지 알아낼수 있지 않을까요?&lt;/p&gt;

&lt;p&gt;중요 포인트는 ‘할인’, ‘비아그라’, ‘세일’ 같은 단어가 나왔다고 무조건 스팸문자는 아니고, &lt;br /&gt;
또한 ‘집’, ‘어디’, ‘간다’, ‘사랑’ 이라는 단어가 나왔다고 무조건 친구나 연인이 보낸 문자로 가정 지으면 안됩니다.&lt;/p&gt;

&lt;p&gt;아래 예제에서는 스팸에서 나온 문자들은 스팸일 확률을 높이는 단어들로 묶고, 햄에서 나온 단어들은 스팸이 아닌 확률로 좀더 높입니다.&lt;/p&gt;

&lt;p&gt;일단 예제에서 사용되는 용어부터 정의하겠습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;용어&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;spam&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;스팸문자&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ham&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;스팸이 아닌 문자&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;라이브러리들을 설치및 import해 줍니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;install.packages&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;tm&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Text Mining Library&lt;/span&gt;
install.packages&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;wordcloud&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
install.packages&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;e1071&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
install.packages&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;gmodels&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;wordcloud&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;tm&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;e1071&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;gmodels&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;데이터를 읽습니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;sms &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; read.delim&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;data.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; header&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; sep&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;\t&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;colnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
sms&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;text &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;text&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;그 다음으로 Data Preparation이 필요합니다. &lt;br /&gt;
문자안에 들어있는 단어들을 통해서 Bayes 확률적으로 이것이 spam 인지 ham인지 알기 위해서는 필요없는 단어들은 제거해주는게 좋습니다.
예를 들어서 but, at, were, was, in 같은 단어들은 그닥 필요가 없으며, 숫자같은 경우 숫자만으로는 spam인지 ham인지 구분짓기가 힘들기 때문에..
숫자또한 제거해 줍니다.&lt;/p&gt;

&lt;p&gt;참고로 corpus는 하나의 글 뭉탱이라고 생각하면 되며, 그냥 sms$text 전체 말뭉치라고 생각하면 됩니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;corpus &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; Corpus&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;VectorSource&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;text&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
corpus.clean &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; tm_map&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; content_transformer&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;tolower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
corpus.clean &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; tm_map&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; removeNumbers&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
corpus.clean &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; tm_map&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; removeWords&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stopwords&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
corpus.clean &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; tm_map&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; removePunctuation&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
corpus.clean &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; tm_map&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stripWhitespace&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
dtm &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; DocumentTermMatrix&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;그 다음으로 75% 데이터는 트레이닝용으로 그리고 나머지는 Naive Bayes를 이용한 스팸 분류가 잘 되는지 퍼포먼스 테스트용으로 사용하겠습니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;sms_raw.train &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; sms&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
sms_raw.test &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; sms&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

dtm.train &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; dtm&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dtm&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),]&lt;/span&gt;
dtm.test &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; dtm&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dtm&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dtm&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

corpus.train &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; corpus.clean&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
corpus.test &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;  corpus.clean&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;as.integer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.clean&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;단어들을 구름 뭉탱으로 봅시다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;wordcloud&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; type&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;spam&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;text&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; min.freq &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; random.order &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
wordcloud&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;subset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; type&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;ham&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;text&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; min.freq &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; random.order &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div style=&quot;text-align:center; font-size:2em;&quot;&gt;Spam&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/posts/Naive-Bayes/spam.png&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;text-align:center; font-size:2em;&quot;&gt;Ham&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/posts/Naive-Bayes/ham.png&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;DocumentTermMatrix는 각각의 문자들 마다 전체 단어중 몇개가 들어 있는지를 나타냅니다.&lt;br /&gt;
예를 들어서. … 다음과 같이 나올수 있습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;sales&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;free&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;now&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;love&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;inspect(sms.train) 해보면 정확하게 볼 수 있는데.. 각각의 SMS 문자마다 전체 단어 중에서 몇개 나왔는지 보여주기 때문에.. 
R 에서 보면 좀 난감한게 좀 있습니다.&lt;/p&gt;

&lt;p&gt;findFreqTerms 같은경우는 전체중에서 5번 이상 나온 단어들만 사용해서 분석하겠다는 뜻입니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;sms.train &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; DocumentTermMatrix&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.train&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;findFreqTerms&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dtm.train&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
sms.test &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;  DocumentTermMatrix&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;corpus.test&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;findFreqTerms&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dtm.test&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;apply함수를 통해서 각각의 메세지를 ‘Yes’, ‘No’ 만 갖고있는 factor로 만들어줌&lt;/p&gt;

&lt;p&gt;* 여리서 MARGIN=1 은 columns를 가르키고, MARGIN=2는 rows를 가르킵니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;convert_counts &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
  x &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;ifelse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  x &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; levels&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; labels&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;No&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;Yes&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;kr&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

sms.train &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms.train&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; MARGIN&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; convert_counts&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
sms.test &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms.test&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; MARGIN&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; convert_counts&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1 id=&quot;training-and-predicting-a-model&quot;&gt;Training and Predicting a model&lt;/h1&gt;

&lt;p&gt;e1071 라이브러리를 사용해서 naive bayes를 처리하도록 하겠습니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;sms_classifier &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; naiveBayes&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms.train&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; sms_raw.train&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;type&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; laplace&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
sms_predictions &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; predict&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms_classifier&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; sms.test&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

CrossTable&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;sms_predictions&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; sms_raw.test&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;type&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

   Cell Contents
&lt;span class=&quot;o&quot;&gt;|-------------------------|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;                       N &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; Chi&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;square contribution &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           N &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; Row Total &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           N &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; Col Total &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;         N &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; Table Total &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;|-------------------------|&lt;/span&gt;

 
Total Observations &lt;span class=&quot;kr&quot;&gt;in&lt;/span&gt; Table&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1394&lt;/span&gt; 

 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; sms_raw.test&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;type 
sms_predictions &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;       ham &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      spam &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; Row Total &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;----------------|-----------|-----------|-----------|&lt;/span&gt;
            ham &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;1200&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;1216&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;19.277&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;128.373&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.987&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.013&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.872&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.990&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.088&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.861&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.011&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;----------------|-----------|-----------|-----------|&lt;/span&gt;
           spam &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;        &lt;span class=&quot;m&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;       &lt;span class=&quot;m&quot;&gt;166&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;       &lt;span class=&quot;m&quot;&gt;178&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;131.691&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;876.974&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.067&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.933&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.128&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.010&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.912&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.009&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.119&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;----------------|-----------|-----------|-----------|&lt;/span&gt;
   Column Total &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;1212&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;       &lt;span class=&quot;m&quot;&gt;182&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;      &lt;span class=&quot;m&quot;&gt;1394&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.869&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;0.131&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;           &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;----------------|-----------|-----------|-----------|&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</description>
        <pubDate>Tue, 04 Aug 2015 11:00:00 +0900</pubDate>
        <link>http://andersonjo.github.io//machine-learning/2015/08/04/Naive-Bayes/</link>
        <guid isPermaLink="true">http://andersonjo.github.io//machine-learning/2015/08/04/Naive-Bayes/</guid>
        
        
        <category>machine-learning</category>
        
      </item>
    
      <item>
        <title>GTX960 + Ubuntu 15.04 + Hello World</title>
        <description>&lt;p&gt;이번에 GTX960 그래픽카드를 질렀습니다.&lt;br /&gt; 
설치 환경은 Ubuntu 15.04 + GTX960 인데, 혹시 나중에 다시 보게 될까봐 여기에다가 적습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/GTX960+Ubuntu15.04+Hello-World/gtx960.jpg&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;acpi-ppc-probe-failed&quot;&gt;ACPI PPC Probe failed&lt;/h3&gt;

&lt;p&gt;GTX960 디바이스를 읽지 못해서 생기는 에러입니다.&lt;/p&gt;

&lt;p&gt;그냥 warning 정도의 에러인데.. 이것과 상관없이.. 화면이 보이지 않는다면..&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;nomodeset&lt;/strong&gt; 옵션을 주고 우분투를 설치또는 로그인하면 됩니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;우분투 설치시에는 F6 (other options)를 눌러서 옵션을 지정할수 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;bit-libraries&quot;&gt;32bit Libraries&lt;/h3&gt;
&lt;p&gt;GTX960 Driver를 설치하기전, 32bit 라이브러리를 설치해줍니다. &lt;br /&gt;
해당 라이브러리는 또한 Android Studio사용시 설치 가능하게 해줍니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386 lib32z1 lib32z1-dev&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;oracle-java&quot;&gt;Oracle Java&lt;/h3&gt;
&lt;p&gt;오라클 자바도 설치합니다. (이건 Nsight등의 IDE를 돌릴때 사용합니다)&lt;/p&gt;

&lt;p&gt;* OpenJDK의 경우 성능이 좀 떨어지는 경우가 있습니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update
sudo apt-get install oracle-java9-installer&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;optional&quot;&gt;벼루 (Optional)&lt;/h3&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo apt-get install uim uim-byeoru
uim-pref-gtk&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;command-prompt--optional&quot;&gt;Command Prompt 설정 (Optional)&lt;/h3&gt;

&lt;p&gt;.bashrc 파일에 추가&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;parse_git_branch&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

    git branch 2&amp;gt; /dev/null &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sed -e &lt;span class=&quot;s1&quot;&gt;&amp;#39;/^[^*]/d&amp;#39;&lt;/span&gt; -e &lt;span class=&quot;s1&quot;&gt;&amp;#39;s/* \(.*\)/ (\1)/&amp;#39;&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PS1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;\[\033[00;36m\]\u:\[\033[0;33m\]\W$(parse_git_branch)&amp;gt;\[\033[00m\]&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;gtx960-driver&quot;&gt;GTX960 Driver&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://www.geforce.com/drivers&quot;&gt;http://www.geforce.com/drivers&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;위의 링크에서 드라이버를 다운받으시고.. 기존의 nvidia 관련 라이브러리를 삭제해줍니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo apt-get remove nvidia* &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; sudo apt-get autoremove&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;이후에 nouveau 라이브러리를 블랙리스트시켜야 추후에 충돌이 없습니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;gksudo gedit /etc/modprobe.d/blacklist-nouveau.conf&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;다음을 추가시켜줍니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;blacklist nouveau
blacklist lbm-nouveau
options nouveau &lt;span class=&quot;nv&quot;&gt;modeset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;0
&lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;nouveau off
&lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;lbm-nouveau off&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Kernel nouveau또한 disable시켜줍니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;echo &lt;/span&gt;options nouveau &lt;span class=&quot;nv&quot;&gt;modeset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; sudo tee -a /etc/modprobe.d/nouveau-kms.conf
sudo update-initramfs -u&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;CUDA Toolkit을 설치시 드라이버만 따로 설치할 필요 없습니다.&lt;br /&gt; 
Cuda Toolkit안에 드라이버까지 포함되어 있습니다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;cuda-toolkit&quot;&gt;CUDA Toolkit&lt;/h3&gt;

&lt;p&gt;아래의 주소에서 RUN파일을 다운로드 받습니다.&lt;br /&gt;
&lt;a href=&quot;https://developer.nvidia.com/cuda-downloads&quot;&gt;https://developer.nvidia.com/cuda-downloads&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;다운받은 폴더로 들어갑니다.&lt;/li&gt;
  &lt;li&gt;chmod로 실행파일로 바꿔줍니다.&lt;/li&gt;
  &lt;li&gt;CTRL + ALT + F3&lt;/li&gt;
  &lt;li&gt;로그인&lt;/li&gt;
  &lt;li&gt;init 3&lt;/li&gt;
  &lt;li&gt;sudo su&lt;/li&gt;
  &lt;li&gt;./NVIDIA*.run 파일 실행&lt;/li&gt;
  &lt;li&gt;reboot&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;reboot 이후에 로그인시 바로 로그 아웃이 되버리면, Ctrl + Alt + F3 누르고 home 에서 .Xauthority를 삭제시켜준다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;cuda-testing&quot;&gt;CUDA Testing&lt;/h3&gt;

&lt;p&gt;Cuda샘플이 설치된 환경으로 이동한다면…&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ./1_Utilities/deviceQuery
make
./deviceQuery&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;파일이 잘 실행이 되는지 확인을 합니다.&lt;/p&gt;

&lt;h3 id=&quot;nsight&quot;&gt;Nsight&lt;/h3&gt;

&lt;p&gt;Toolkit 을 설치하게 되면 자동으로 Eclipse Nsight가 설치가 되어 있습니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;Hello World&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;위의 코드처럼 짠 다음에..&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;nvcc hello.c -o hello
hello&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;실행하면 뭐.. Hello World 프린트가 찍힙니다.&lt;/p&gt;

&lt;h3 id=&quot;saving-a-new-x-configuration&quot;&gt;Saving a new X Configuration&lt;/h3&gt;

&lt;p&gt;Nvidia 드라이버 설치시 자동으로 해주긴 하지만.. 혹시 새롭게 다시 재정의 필요시 다음의 명령어를 실행시켜줍니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo nvidia-xconfig&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;low---&quot;&gt;검은화면, Low 그래픽 화면.. 에러&lt;/h3&gt;

&lt;p&gt;에러가 일어났을 경우에만.. 다음의 라이브러리들을 설치합니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo apt-get install dkms fakeroot build-essential linux-headers-generic&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 03 Aug 2015 11:00:00 +0900</pubDate>
        <link>http://andersonjo.github.io//ubuntu/2015/08/03/GTX960+Ubuntu+Cuda/</link>
        <guid isPermaLink="true">http://andersonjo.github.io//ubuntu/2015/08/03/GTX960+Ubuntu+Cuda/</guid>
        
        
        <category>ubuntu</category>
        
      </item>
    
      <item>
        <title>Monty Hall Problem - Bayes</title>
        <description>&lt;p&gt;&lt;img src=&quot;/assets/posts/Monty-Hall-Problem/saw-play-a-game.jpg&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;당신은 전날밤 술에 취했고 깨어나보니 어두운 방에 갖혀 있었다. &lt;br /&gt;
흐릿했던 초점이 돌아오고 정신이 드니 눈앞에 직소가 있었고 옆에는 3개의 문이 있다.&lt;br /&gt;
그리고 직소는 당신과 게임을 하길 원한다.&lt;br /&gt;
게임의 룰은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;3개의 문이 있다.&lt;/li&gt;
  &lt;li&gt;단 하나의 문 뒤에 살아나갈수 있는 열쇠가 있다.&lt;/li&gt;
  &lt;li&gt;게임의 시작은 당신이 먼저 열쇠가 있을거 같은 문을 선택을 한다. (선택만하고 문은 열지 않는다)&lt;/li&gt;
  &lt;li&gt;직소는 선택하지 않은 문 2개중에 열쇠가 없는 문을 연다. (즉 직소는 당연히 열쇠가 어디 있는지 알고 있다.)&lt;/li&gt;
  &lt;li&gt;그리고 당신에게 선택이 주어진다. 처음에 선택한 문을 열것인가? 아니면 결정을 바꾸고 다른 문을 선택할 것인가?&lt;/li&gt;
  &lt;li&gt;열쇠가 있는 문을 선택하면 살고, 뒤에 아무것도 없으면 죽는거임&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;자.. 먼저 아래의 내용을 보시기 전에 당신의 선택은 어떻게 하시겠습니까?&lt;/p&gt;

&lt;p&gt;또 그렇게 결정한 이유가 무었입니까?&lt;/p&gt;

&lt;h1 id=&quot;conditional-probability&quot;&gt;Conditional Probability&lt;/h1&gt;

&lt;p&gt;보통 2개의 이벤트(상황)이 있는데 서로 영향을 미치는(dependent) 상황일때 사용을 합니다.
예를 들어서 담배를 많이 필수록 폐암에 걸릴 확률이라든가, 오늘 비가온다면 내일 비가 올 확률이 좀 더 높다든가.. 
하여튼 어떠한 이벤트의 경우에 따라서 다른 이벤트에 영향을 주는 경우에 Conditional Probability 사용이 가능합니다.&lt;/p&gt;

&lt;p&gt;다음은 그냥 몇가지 공식을 적어드립니다. &lt;br /&gt;
그냥 묻지도 따지지도 말고 그냥 왜우면 되요 :) &lt;em&gt;(이런걸 Axiom이라고 하죠..)&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A라는 이벤트가 일어날 확률은 &lt;strong&gt;P(A)&lt;/strong&gt; 이렇게 적습니다.&lt;br /&gt;
&lt;span style=&quot;color:#777; font-size:0.9em;&quot;&gt;ex) P(head) 동전의 앞면이 나올 확률&lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;그런데 B라는 조건하에 A라는 이벤트가 일어날 확률은 &lt;strong&gt;P(A|B)&lt;/strong&gt; 이렇게 적습니다. &lt;br /&gt;
&lt;span style=&quot;color:#777; font-size:0.9em;&quot;&gt;ex) P(암|담배) 담배를 피울때 암에 걸릴 확률&lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;P(A and B) = P(A)P(B|A)&lt;/strong&gt;&lt;br /&gt;
&lt;span style=&quot;color:#777; font-size:0.9em;&quot;&gt;A 와 B는 dependent 이며 A 그리고 B 가 동시에 일어날 경우.. &lt;br /&gt;
 참고로 A 와 B 가 independent라면 &lt;strong&gt;P(A)P(B)&lt;/strong&gt; 로 표현될수 있습니다.&lt;br /&gt; 
 가령 동전 A가 앞면이고, 동전 B가 앞면일 확률&lt;br /&gt; 
 0.5 * 0.5 = 0.25
&lt;/span&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;P(A and B) = P(B and A)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그런데 말입니다?!
&lt;img src=&quot;/assets/posts/Monty-Hall-Problem/but-the-thing.jpg&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/Monty-Hall-Problem/f101.gif&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/Monty-Hall-Problem/f102.gif&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서..&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/Monty-Hall-Problem/f103.gif&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;즉 서로 바꿔 쓸수 있으며 아주 중요한 내용이다. 여기서 조금더 나가면.. 바로.. 그 유명한 Bayes Formula 를 얻을수 있다.&lt;/p&gt;

&lt;p&gt;=====================================
&lt;img src=&quot;/assets/posts/Monty-Hall-Problem/formula.gif&quot; class=&quot;img-responsive img-rounded&quot; /&gt;
=====================================&lt;/p&gt;

&lt;p&gt;위의 공식을 통해서 직소 문제를 풀어보도록 하겠습니다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bayes라고 쓰는 이유는 그냥 옛날 옛적에 베이즈라는 사람이 만들어서 그 사람 이름 딴 거임 ..&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;monty-hall-problem&quot;&gt;Monty Hall Problem&lt;/h1&gt;

&lt;p&gt;여름이라서 직소를 내보냈는데.. 사실 이 문제는 Monty Hall Problem이라고 해서 실제 외국 TV쇼에서 했었던 문제입니다.
궁금하면 집접 찾아보시길.. 다른게 있다면 3개중에 한개에는 “자동차”같이 짱짱맨 선물이 있다는거&lt;/p&gt;

&lt;p&gt;당시에 학계? 에서는 이 Monty Hall Problem으로 논란?이 된 적도 있었습니다. 실제 당시의 저명한 교수가 TV에 출연해서.. 
처음 선택한걸 열거나 또는 바꾸거나 확률은 그게 그거다 라고 아주 열띄게 강조도 했었을 정도였으니…&lt;/p&gt;

&lt;p&gt;상식적으로 생각하면.. 어차피 3개의 문에 랜덤으로 키가 있는거고.. 나는 그 랜덤 중에서 고르는 것인데..
처음걸 선택하거나 또는 원래 선택에서 바꾸는게 그렇게 큰 의미가 있을까? 생각이 들 수도 있습니다.&lt;/p&gt;

&lt;p&gt;자.. 위에서 배운 Bayes 공식으로 문제를 풀어보도록 하겠습니다.&lt;br /&gt;
대충 상황은 다음과 같다고 가정을 하겠습니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;문 A, B, C 가 있다.&lt;/li&gt;
  &lt;li&gt;당신은 A문을 최초로 선택을 했다. (문은 열지 않았다.)&lt;/li&gt;
  &lt;li&gt;직소는 B의 문을 열었고, B문의 뒤에는 아무것도 없었다. (직소는 어디에 열쇠가 있는지 알고 있다.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;첫번째 이벤트 P(Jigsaw Opens B)는 직소가 문 B를 열었다는 것이고.. &lt;br /&gt;
두번째 이벤트 P(Key@..) 는 여러분이 어디 문을 열었을때의 확률입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/Monty-Hall-Problem/monty_formula.gif&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;P(key@..)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;P(jigsaw Opens B|Key@..)&lt;/th&gt;
      &lt;th&gt;P(Key@..)P(jigsaw Opens B|Key@..)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;A문&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;P(key@A) = 1/3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;P(jigsaw Opens B|Key@A) = 1/2&lt;/td&gt;
      &lt;td&gt;1/3 * 1/2 = 1/6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;B문&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;P(key@B) = 1/3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;P(jigsaw Opens B|Key@B) = 0&lt;/td&gt;
      &lt;td&gt;1/3 * 0 = 0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;C문&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;P(key@C) = 1/3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;P(jigsaw Opens B|Key@C) = 1&lt;/td&gt;
      &lt;td&gt;1/3 * 1 = 1/3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;공식에 따르면 P(Jigsaw Opens B) 의 확률을 구해야 하는데 어차피 하나마나라서 안해도 됩니다.&lt;br /&gt;
참고로 P(Jigsaw Opens B)의 값은 1/2 입니다. 당신이 문을 선택하고, Jigsaw가 선택할수 있는 문의 확률&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;P(Key@A) 라는 뜻은 A의 문을 열 확률입니다.&lt;/li&gt;
  &lt;li&gt;P(Jigsaw Opens B|Key@B) 라는 뜻은 키가 B에 있을때, 직소가 B를 열 확률인데.. 당연히 B에 있는데 열리가 없겠죠&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:red&quot;&gt;
&lt;strong&gt;결론적으로 키가 A에 있을 확률은 1/6 이고, B에 있을 확률은 1/3입니다.&lt;br /&gt;&lt;/strong&gt;
&lt;strong&gt;즉 2배 차이가 나며 베이즈 확률에 따르면, 원래 선택했던거 말고 바꾸는 것이 살아날 확률을 2배 정도 높입니다&lt;/strong&gt;
&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;아래의 동영상을 보시면.. 중간쯤에 실제로 실험을 합니다.&lt;br /&gt;
검을색 옷을 입은 남자는 자기가 최초에 선택한 컵을 선택하고 기회가 주어졌을때 바꾸지 않습니다.&lt;br /&gt;
빨간색 옷을 입은 남자는 기회가 주어졌을때 무조건 다른것을 선택합니다. &lt;br /&gt;
실제 실험을 했을때 검을색 옷의 남자는 2대의 자동차밖에 못 얻었지만, 빨간색 옷 남자는 16대의 자동차를 얻습니다.&lt;br /&gt;
뭐 2배 이상을 훨씬 뛰어 넘었네요..&lt;/p&gt;

&lt;iframe width=&quot;420&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/o_djTy3G0pg&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;자.. 그래서 결론은..&lt;br /&gt;
데이터 사이언티스트들이 이런 Bayes 확률로 어떻게 뭘 할건데? 이런거인데요..&lt;br /&gt;
이거는 언젠가 시간이 나면 다루도록 하겠습니다.&lt;br /&gt;
실무에서는 주로 Text Classification 에서 활용이 되고 있습니다.&lt;br /&gt;
다른 Machine Learning 알고리즘보다 복잡하지 않으면서 강력하게 활용이 될 수 있습니다.&lt;/p&gt;
</description>
        <pubDate>Wed, 29 Jul 2015 11:00:00 +0900</pubDate>
        <link>http://andersonjo.github.io//machine-learning/2015/07/29/Monty-Hall-Problem/</link>
        <guid isPermaLink="true">http://andersonjo.github.io//machine-learning/2015/07/29/Monty-Hall-Problem/</guid>
        
        
        <category>machine-learning</category>
        
      </item>
    
      <item>
        <title>Neural Network for Concrete Strength using R</title>
        <description>&lt;div&gt;
    &lt;img src=&quot;/assets/posts/Neural-Network-for-concrete/concrete.jpg&quot; class=&quot;img-responsive img-rounded&quot; /&gt;
&lt;/div&gt;
&lt;p&gt;신경망이라는 주제는 Machine Learning분야에서 80년대부터 계속해서 발전해온 기술입니다.&lt;br /&gt;
맛보기로 R을 사용해서 신경망(Neural Network)을 해보도록 하겠습니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;콘크리트의 퍼포먼스 즉 강도(Strength)를 결정하는데에는 많은 변수들이 있습니다.&lt;br /&gt;
들어가는 재료들의 양에 따라서 콘크리트의 강도가 달라지기 때문에 여기에는 특별한 수학적 공식을 얻어내기가 쉽지가 않습니다. &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Neural Network를 이용하면 특별한 수학적 공식 (콘크리트의 강도를 알아내는..) 없이 ANN(Artificial Neural Network)을 트레이닝 시키고
훈련된 ANN으로 다시 새로운 데이터로 예측을 할 것입니다.&lt;br /&gt;&lt;/p&gt;

&lt;h3&gt;Data &amp;amp; References&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;/assets/posts/Neural-Network-for-concrete/concrete.csv&quot;&gt;concrete.csv&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;/assets/posts/Neural-Network-for-concrete/example.R&quot;&gt;example.R&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://www.amazon.com/Machine-Learning-R-Brett-Lantz/dp/1782162143/ref=sr_1_1?ie=UTF8&amp;amp;qid=1437813079&amp;amp;sr=8-1&amp;amp;keywords=machine+learning+with+r&quot;&gt;Machine Learning with R&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Neuralnet 설치 &lt;/h3&gt;

&lt;p&gt;여러 Neural Network 라이브러리들이 있지만.. Neuralnet이라는 라이브러리를 사용할 것입니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;install.packages&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;neuralnet&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;일단 코드로 써보자&lt;/h3&gt;

&lt;p&gt;read.csv 함수를 통해서 concrete.csv파일을 읽습니다.&lt;br /&gt;
stringAsFactors는 R의 데이터타입중에 string을 factor로 읽지 않고  vector로 읽겠다는 뜻이며, F는 FALSE(boolean)값과 같습니다.&lt;br /&gt;
끝에 [-1]은 첫번째 row 필드값을 exclude시키겠다는 말..&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;포인트는.. cement, flag, ash, water, superplastic, coarseagg, findagg, age 등등 다양한 요소가 모여서 궁극적으로 strength를
결정을 하게 됩니다. 각각의 재료및 요소에 따라서 strength의 값이 달라지는데.. 역시 정확한 공식을 얻기는 쉽지 않겠죠..&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;concrete &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;concrete.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stringsAsFactors &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;concrete&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  cement  flag ash water superplastic coarseagg findagg age strength
&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;540.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;162&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;2.5&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;1040.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;676.0&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;28&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;79.99&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;540.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;162&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;2.5&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;1055.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;676.0&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;28&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;61.89&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;332.5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;142.5&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;228&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;0.0&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;932.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;594.0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;270&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;40.27&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;332.5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;142.5&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;228&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;0.0&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;932.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;594.0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;365&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;41.05&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;198.6&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;132.4&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;192&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;0.0&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;978.4&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;825.5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;360&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;44.30&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;266.0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;114.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;228&lt;/span&gt;          &lt;span class=&quot;m&quot;&gt;0.0&lt;/span&gt;     &lt;span class=&quot;m&quot;&gt;932.0&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;670.0&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;90&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;47.03&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;데이터를 살펴보니.. 각각의 필드들이 제각각의 범위의 값을 갖고 있습니다. 즉.. Normalize가 필요합니다.&lt;br /&gt;
여러방법의 normalize가 있는데 우리는 min max normalize를 사용하겠습니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;normalize &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kr&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;x &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
concrete &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;lapply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;concrete&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; normalize&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;concrete&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        cement         flag ash        water  superplastic    coarseagg      findagg           age     strength
&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.0000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.0000000000&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3210862620&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.07763975155&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.6947674419&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2057200201&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.07417582418&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.9674847390&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.0000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.0000000000&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3210862620&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.07763975155&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.7383720930&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2057200201&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.07417582418&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.7419957643&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5262557078&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3964941569&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.8482428115&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.00000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3808139535&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.0000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.73901098901&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.4726547901&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5262557078&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3964941569&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.8482428115&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.00000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3808139535&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.0000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1.00000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.4823719945&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.2205479452&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3683917641&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5607028754&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.00000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5156976744&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5807827396&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.98626373626&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5228603463&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3744292237&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3171953255&lt;/span&gt;   &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.8482428115&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.00000000000&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.3808139535&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.1906673357&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.24450549451&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.5568705619&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;lapply함수에 바로 dataframe type을 넣을수가 있고 lapply는 각각의 필드마다 normalize함수를 진행하게 됩니다.&lt;br /&gt;
가장 큰 값은 1이 되었고.. 가장 작은 값은 0으로 normalize를 하였습니다.&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
만약 lapply를 사용하지 않고 바로 normalize(concrete) 를 사용하게 되면.. dataframe내에서 가장 큰 값이 1을 갖고, 가장 작은 값이 0을
갖게 됩니다. 즉 cement필드에서 0~1 또는.. water에서 0~1값을 갖는게 아니라.. 전체 dataframe내에서 normalize를 하게 되며..
이는 우리가 원하는 결과값이 아닙니다.
&lt;/blockquote&gt;

&lt;p&gt;그 다음으로.. concrete 데이터의 75%를 트레이닝용으로 사용하고, 나머지는 해당 neural network가 제대로 돌아가는지 검증용으로 사용을 할
것입니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;max_index &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;concrete&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;strength&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
slice_index &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;max_index &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
training_data &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; concrete&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;slice_index&lt;span class=&quot;p&quot;&gt;,]&lt;/span&gt;
test_data &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; concrete&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;slice_index&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;max_index&lt;span class=&quot;p&quot;&gt;,]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Neural Network 트레이닝 시키기&lt;/h3&gt;
&lt;p&gt;자 이제 모든 준비가 끝났으니 Neural Network를 트레이닝 시키겠습니다. &lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;concrete_model &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;
  neuralnet&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;strength &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt; cement &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; flag &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; ash &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; water &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; superplastic &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; coarseagg &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      findagg &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; age&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; data &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; training_data&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; hidden &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
plot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;concrete_model&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# plot the neural networks&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/posts/Neural-Network-for-concrete/neuralnet_hidden_3.png&quot; class=&quot;img-responsive img-rounded&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림에 보면 8개의 nodes가 보입니다. 이것을 Input Nodes라고 부릅니다.&lt;br /&gt;
중간에 3개의 원이 있는데 이것을 Hidden Nodes라고 부릅니다.&lt;br /&gt;
마지막 제일 오른쪽에 1개의 원이있는데 이것을 Output Node라고 부릅니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Backpropagation이 있는데.. 트레이닝중에 틀리거나 맞는것이 있을때마다 결과치에 따라서 각각의 Nodes들의 수치를 변경하게 됩니다.&lt;br /&gt;
즉 각각의 Nodes들에는 서로 연결되어있어서 강하게 연결되어 있는것이 있고, 약하게 연결된것이 있는데..
Backpropagation을 통해서 이 가중치를 변경을 하게 되는 것입니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;아! 참고로 최초로 Nodes들이 연결이 될때는 어떻게 가중치를 주는가? 인데..
최초에는 랜덤값을 그냥 넣습니다. 따라서 여러분이 집접 저 코드를 돌려보면 매번 다른 값이 나오게 될 것입니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;자! 그렇다면 이렇게 학습된 Neural Network의 성능시험이 필요하지 않을까요?
처음에 75%데이터를 학습으로 사용했으니, 나머지 데이터를 이용해서 정확하게 예측을 하는지 검사해봅시다.&lt;br /&gt;&lt;/p&gt;

&lt;h3&gt; Neural Network 성능측정 (Prediction) &lt;/h3&gt;

&lt;p&gt;성능측정은 상관관계분석(Correlation)을 통해서 측정을 하게 됩니다.&lt;br /&gt;
1값이 나올수록 예측의 정확성이 높다는 뜻이고, 0값이 나온다면 예측값이 떨어진다는 뜻입니다.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;model_results &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; compute&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;concrete_model&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
cor&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;model_results&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;net.result&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; test_data&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;strength&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;0.8201494476&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt; Facebook &lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.facebook.com/groups/codingeverybody/permalink/1027643290609540/&quot;&gt;Facebook Link&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 26 Jul 2015 00:00:00 +0900</pubDate>
        <link>http://andersonjo.github.io//neural-network/2015/07/26/Neural-Network-for-concrete/</link>
        <guid isPermaLink="true">http://andersonjo.github.io//neural-network/2015/07/26/Neural-Network-for-concrete/</guid>
        
        
        <category>neural-network</category>
        
      </item>
    
      <item>
        <title>Anderson Page Opened</title>
        <description>&lt;p&gt;안녕하세요 &lt;br /&gt;
개발자 조창민입니다. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Python, R, Machine Learning, Data Analysis, AWS, Android 등등의 개발 관련하여 포스팅을 할 예정입니다.&lt;br /&gt;
헤헤헤헤헤&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hello&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Hello Wolrd!&amp;#39;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;hello&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;비즈니스및 문의사항은 &lt;i&gt;a141890@gmail.com&lt;/i&gt; 로 연락을 주세요. &lt;br /&gt;
제 영문 이력서는 &lt;a href=&quot;https://kr.linkedin.com/in/anderdson&quot;&gt;링크드인&lt;/a&gt;을 확인해주세요.&lt;/p&gt;

</description>
        <pubDate>Sat, 25 Jul 2015 21:56:02 +0900</pubDate>
        <link>http://andersonjo.github.io//init/2015/07/25/welcome-to-jekyll/</link>
        <guid isPermaLink="true">http://andersonjo.github.io//init/2015/07/25/welcome-to-jekyll/</guid>
        
        
        <category>init</category>
        
      </item>
    
  </channel>
</rss>
